# -*- coding: utf-8 -*-
"""yazilimstaj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JBXdJhMLXTaOtZKC7Ky3-eb1aeizeHLP
"""

!pip -q install python-docx
import pandas as pd, numpy as np, matplotlib.pyplot as plt, datetime as dt, os
from matplotlib.backends.backend_pdf import PdfPages
from docx import Document
from docx.shared import Inches
import datetime as dt,os
from google.colab import files
uploaded=files.upload(); csv_name=list(uploaded.keys())[0]; print("Yüklenen dosya:",csv_name); df=pd.read_csv(csv_name); print(df.shape); df.head()

# ==== 2. ŞEMA & KOLON KONTROL ====
print("Sütunlar:", df.columns.tolist())
print("\nBilgi:")
print(df.info())

print("\nÖrnek 5 satır:")
display(df.head())

print("\nKısa istatistikler (sayısal):")
display(df.describe())

# ==== 3. BASİT TEMİZLİK ====
df_clean = df.copy()

# Age değerleri çok küçük olanları NaN yap (ör: <16)
df_clean.loc[df_clean['Age'] < 16, 'Age'] = np.nan

# Aykırı değerleri çok uçsa kırp (winsorize mantığı – isteğe bağlı)
df_clean['Age'] = df_clean['Age'].clip(lower=16, upper=80)
df_clean['LengthService'] = df_clean['LengthService'].clip(lower=0, upper=df_clean['LengthService'].quantile(0.99))
df_clean['AbsentHours'] = df_clean['AbsentHours'].clip(lower=0, upper=df_clean['AbsentHours'].quantile(0.99))

print("Temizlik sonrası özet:")
display(df_clean[['Age','LengthService','AbsentHours']].describe())

# ==== 4. KATEGORİK & SAYISAL LİSTELER ====
cat_cols = ['Gender','City','JobTitle','DepartmentName','StoreLocation','Division','BusinessUnit','Surname','GivenName']
num_cols = ['EmployeeNumber','Age','LengthService','AbsentHours']

print("Kategorik:", cat_cols)
print("Sayısal:", num_cols)

# ==== 5.a CİNSİYETE GÖRE DEVAMSIZLIK ====
gender_abs = df_clean.groupby('Gender')['AbsentHours'].agg(['mean','sum','count']).sort_values('mean', ascending=False)
display(gender_abs)

# ==== 5.b ŞEHRE GÖRE DEVAMSIZLIK (TOP 15) ====
city_abs = (df_clean.groupby('City')['AbsentHours']
            .sum()
            .sort_values(ascending=False)
            .head(15))
display(city_abs)

# ==== 5.c DEPARTMANA GÖRE ORTALAMA DEVAMSIZLIK (TOP 15) ====
dept_abs = (df_clean.groupby('DepartmentName')['AbsentHours']
            .mean()
            .sort_values(ascending=False)
            .head(15))
display(dept_abs)

# ==== 5.d İŞ UNVANINA GÖRE TOPLAM DEVAMSIZLIK (TOP 15) ====
job_abs = (df_clean.groupby('JobTitle')['AbsentHours']
           .sum()
           .sort_values(ascending=False)
           .head(15))
display(job_abs)

# ==== 6.a CİNSİYETE GÖRE ORTALAMA DEVAMSIZLIK (BAR) ====
plot_series = df_clean.groupby('Gender')['AbsentHours'].mean().sort_values(ascending=False)

plt.figure(figsize=(6,4))
plot_series.plot(kind='bar')
plt.title('Cinsiyete Göre Ortalama AbsentHours')
plt.ylabel('Saat')
plt.xlabel('Gender')
plt.tight_layout()
plt.show()

# ==== 6.b ŞEHRE GÖRE TOPLAM DEVAMSIZLIK (TOP 10) ====
plot_series = (df_clean.groupby('City')['AbsentHours']
               .sum()
               .sort_values(ascending=False)
               .head(10))

plt.figure(figsize=(10,5))
plot_series.plot(kind='bar')
plt.title('Şehre Göre Toplam AbsentHours (Top 10)')
plt.ylabel('Saat')
plt.xlabel('City')
plt.tight_layout()
plt.show()

# ==== 6.c DEPARTMANA GÖRE ORTALAMA DEVAMSIZLIK (TOP 10) ====
plot_series = (df_clean.groupby('DepartmentName')['AbsentHours']
               .mean()
               .sort_values(ascending=False)
               .head(10))

plt.figure(figsize=(10,5))
plot_series.plot(kind='bar')
plt.title('Departmana Göre Ortalama AbsentHours (Top 10)')
plt.ylabel('Saat')
plt.xlabel('DepartmentName')
plt.tight_layout()
plt.show()

# ==== 6.d İŞ UNVANINA GÖRE TOPLAM DEVAMSIZLIK (TOP 10) ====
plot_series = (df_clean.groupby('JobTitle')['AbsentHours']
               .sum()
               .sort_values(ascending=False)
               .head(10))

plt.figure(figsize=(10,5))
plot_series.plot(kind='bar')
plt.title('İş Unvanına Göre Toplam AbsentHours (Top 10)')
plt.ylabel('Saat')
plt.xlabel('JobTitle')
plt.tight_layout()
plt.show()

# ==== 7. KORELASYON MATRİSİ ====
corr = df_clean[['Age','LengthService','AbsentHours']].corr()
display(corr)

plt.figure(figsize=(4,3))
plt.imshow(corr, interpolation='nearest')
plt.title('Korelasyon (Age, LengthService, AbsentHours)')
plt.colorbar()
plt.xticks(range(len(corr.columns)), corr.columns, rotation=45)
plt.yticks(range(len(corr.columns)), corr.columns)
plt.tight_layout()
plt.show()

# ==== 8. ÖZET RAPOR ====
summary = df_clean[['Age','LengthService','AbsentHours']].agg(['min','median','mean','max']).T
summary.columns = ['min','median','mean','max']
display(summary)

# ==== 9. YARDIMCI FONKSİYONLAR ====
def top_n_sum(col, n=10):
    return (df_clean.groupby(col)['AbsentHours']
            .sum()
            .sort_values(ascending=False)
            .head(n))

def top_n_mean(col, n=10):
    return (df_clean.groupby(col)['AbsentHours']
            .mean()
            .sort_values(ascending=False)
            .head(n))

print(top_n_sum('City', 10))
print()
print(top_n_mean('DepartmentName', 10))

import matplotlib.pyplot as plt

def top_n_sum_plot(col,n=10):
    data=df_clean.groupby(col)['AbsentHours'].sum().sort_values(ascending=False).head(n)
    data.plot(kind='bar',figsize=(8,4),title=f"Toplam AbsentHours by {col} (Top {n})")
    plt.ylabel("Toplam Saat")
    plt.xlabel(col)
    plt.xticks(rotation=45)
    plt.show()

def top_n_mean_plot(col,n=10):
    data=df_clean.groupby(col)['AbsentHours'].mean().sort_values(ascending=False).head(n)
    data.plot(kind='bar',figsize=(8,4),title=f"Ortalama AbsentHours by {col} (Top {n})")
    plt.ylabel("Ortalama Saat")
    plt.xlabel(col)
    plt.xticks(rotation=45)
    plt.show()

top_n_sum_plot("City",10)          # Şehirlere göre toplam devamsızlık
print()
top_n_mean_plot("DepartmentName",5) # Departmanlara göre ortalama devamsızlık

"""Otomatik Rapor"""

from matplotlib.backends.backend_pdf import PdfPages
from docx import Document
from docx.shared import Inches
import matplotlib.pyplot as plt,datetime as dt,os

# kolon-listesi
charts=[("City","sum",10),("DepartmentName","mean",10),("JobTitle","sum",10),("Gender","mean",2),("StoreLocation","sum",10),("Division","sum",10),("BusinessUnit","mean",10)]

# zaman damgaları ve dosya adları
stamp=dt.datetime.now().strftime("%Y-%m-%d_%H-%M")
pdf_name=f"Absenteeism_Report_{stamp}.pdf"
docx_name=f"Absenteeism_Report_{stamp}.docx"
img_files=[]

# yardımcı: seri üret (sum/mean) ve figür çiz
def make_series(df,col,mode,topn):
    if col not in df.columns: return None
    s=df.groupby(col)['AbsentHours'].sum().sort_values(ascending=False).head(topn) if mode=="sum" else df.groupby(col)['AbsentHours'].mean().sort_values(ascending=False).head(topn)
    return s if not s.empty else None
def plot_series(s,title,xlabel):
    fig=plt.figure(figsize=(10,4)); s.plot(kind="bar"); plt.title(title); plt.ylabel("Saat"); plt.xlabel(xlabel); plt.xticks(rotation=45); plt.tight_layout(); return fig

# === PDF üret (kapak + grafikler) ===
with PdfPages(pdf_name) as pdf:
    cover=plt.figure(figsize=(8.27,11.69)); plt.text(0.5,0.62,"Employee Absenteeism Raporu",ha="center",va="center",fontsize=22); plt.text(0.5,0.55,f"Tarih: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')}",ha="center",va="center",fontsize=12); plt.axis("off"); pdf.savefig(cover,bbox_inches="tight"); plt.close(cover)
    for col,mode,topn in charts:
        s=make_series(df_clean,col,mode,topn)
        if s is None: continue
        title=f"{'Toplam' if mode=='sum' else 'Ortalama'} AbsentHours by {col} (Top {topn})"
        fig=plot_series(s,title,col)
        img=f"{col}_{mode}_{stamp}.png"
        fig.savefig(img,dpi=150,bbox_inches="tight")
        pdf.savefig(fig,bbox_inches="tight")
        plt.close(fig)
        img_files.append((img,title))

# === Word üret ===
doc=Document()
doc.add_heading("Employee Absenteeism – Otomatik Rapor",0)
doc.add_paragraph(f"Oluşturma tarihi: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')}")
doc.add_paragraph("Bu rapor df_clean veri çerçevesinden üretilmiştir. Grafikler AbsentHours metriklerini farklı kategorik değişkenlere göre özetler.")
for img,title in img_files:
    if os.path.exists(img):
        doc.add_heading(title,level=2)
        doc.add_picture(img,width=Inches(6))
doc.save(docx_name)

print("✓ PDF kaydedildi:",pdf_name)
print("✓ Word kaydedildi:",docx_name)
print("✓ Görseller:",[i for i,_ in img_files])

from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt,datetime as dt,os
stamp=dt.datetime.now().strftime("%Y-%m-%d_%H-%M")
pdf_name=f"Absenteeism_Report_{stamp}.pdf"
with PdfPages(pdf_name) as pdf:
    # Kapak sayfası (PDF'in oluştuğunu garanti eder)
    fig=plt.figure(figsize=(8.27,11.69)); plt.text(0.5,0.6,"Employee Absenteeism Raporu",ha="center",va="center",fontsize=20); plt.text(0.5,0.5,f"Tarih: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')}",ha="center",va="center",fontsize=12); plt.axis("off"); pdf.savefig(fig,bbox_inches="tight"); plt.close(fig)
    # Örnek grafikler (kolon varsa ekler)
    charts=[("City","sum",10),("DepartmentName","mean",10),("JobTitle","sum",10),("Gender","mean",2)]
    for col,mode,topn in charts:
        if col not in df_clean.columns: continue
        if mode=="sum":
            s=df_clean.groupby(col)['AbsentHours'].sum().sort_values(ascending=False).head(topn)
        else:
            s=df_clean.groupby(col)['AbsentHours'].mean().sort_values(ascending=False).head(topn)
        if s.empty: continue
        fig=plt.figure(figsize=(10,4)); s.plot(kind="bar"); plt.title(f"{'Toplam' if mode=='sum' else 'Ortalama'} AbsentHours by {col} (Top {topn})"); plt.ylabel("Saat"); plt.xlabel(col); plt.xticks(rotation=45); plt.tight_layout(); pdf.savefig(fig,bbox_inches="tight"); plt.close(fig)
# Oluştu mu? Boyutunu ve dizini yazdır
exists=os.path.exists(pdf_name); size=os.path.getsize(pdf_name) if exists else 0
print("✓ PDF adı:",pdf_name)
print("✓ Var mı?",exists,"| Boyut (bayt):",size)
print("Dizindeki dosyalar:",os.listdir("/content"))

import os
os.listdir("/content")

from google.colab import files
files.download("Absenteeism_Report_2025-08-28_06-07.pdf")
files.download("Absenteeism_Report_2025-08-28_06-07.docx")

"""DepartmentName + City + JobTitle için KPI tabloları"""

!pip -q install python-pptx
import matplotlib.pyplot as plt,pandas as pd,numpy as np,datetime as dt,os
from pptx import Presentation
from pptx.util import Inches
stamp=dt.datetime.now().strftime("%Y-%m-%d_%H-%M"); pptx_name=f"Absenteeism_Summary_{stamp}.pptx"; prs=Presentation()
def make_series(df,col,mode,topn):
    if col not in df.columns or 'AbsentHours' not in df.columns: return None
    s=df.groupby(col)['AbsentHours'].sum().sort_values(ascending=False).head(topn) if mode=="sum" else df.groupby(col)['AbsentHours'].mean().sort_values(ascending=False).head(topn)
    return s if not s.empty else None
def plot_series(s,title,xlabel,filename):
    fig=plt.figure(figsize=(10,4)); s.plot(kind="bar"); plt.title(title); plt.ylabel("Saat"); plt.xlabel(xlabel); plt.xticks(rotation=45); plt.tight_layout(); fig.savefig(filename,dpi=150,bbox_inches="tight"); plt.close(fig); return filename
def kpi_table(df,group_col,topn=10):
    if group_col not in df.columns or 'AbsentHours' not in df.columns: return None
    g=df.groupby(group_col)['AbsentHours']; out=pd.DataFrame({"N":g.count(),"Sum":g.sum(),"Mean":g.mean()}).sort_values("Sum",ascending=False).head(topn); out["%Contribution"]=(out["Sum"]/out["Sum"].sum()*100).round(1); return out.reset_index()
title_slide=prs.slides.add_slide(prs.slide_layouts[0]); title_slide.shapes.title.text="Employee Absenteeism – Özet Sunum"; title_slide.placeholders[1].text=f"Tarih: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')}"
meth_slide=prs.slides.add_slide(prs.slide_layouts[1]); meth_slide.shapes.title.text="Yöntem (Kısa)"; tx=meth_slide.shapes.placeholders[1].text_frame; tx.text="• Kaynak: df_clean (CSV/Excel), Python pandas"; p=tx.add_paragraph(); p.text="• Temizlik: Age<16 düzeltildi; uç değerler clip"; p=tx.add_paragraph(); p.text="• Analiz: AbsentHours toplam/ortalama; City/Department/Job/Gender"; p=tx.add_paragraph(); p.text="• Çıktı: Grafikler + PDF/DOCX/PPTX"
charts=[("City","sum",10),("DepartmentName","mean",10),("JobTitle","sum",10),("Gender","mean",2)]; imgs=[]
for col,mode,topn in charts:
    s=make_series(df_clean,col,mode,topn)
    if s is None: continue
    title=f"{'Toplam' if mode=='sum' else 'Ortalama'} AbsentHours by {col} (Top {topn})"; fp=f"{col}_{mode}_{stamp}.png"; imgs.append((plot_series(s,title,col,fp),title))
for fp,title in imgs:
    sl=prs.slides.add_slide(prs.slide_layouts[5]); sl.shapes.title.text=title; sl.shapes.add_picture(fp,Inches(0.7),Inches(1.8),width=Inches(8.3))
for group_col in ["DepartmentName","City","JobTitle"]:
    kpi=kpi_table(df_clean,group_col,10)
    if kpi is None or kpi.empty: continue
    sl=prs.slides.add_slide(prs.slide_layouts[5]); sl.shapes.title.text=f"KPI Tablosu – İlk 10 {group_col}"
    rows,cols=kpi.shape; rows=rows+1
    x,y,w,h=Inches(0.5),Inches(1.6),Inches(9.0),Inches(4.5); tbl=sl.shapes.add_table(rows,cols,x,y,w,h).table
    for j,col in enumerate(kpi.columns): tbl.cell(0,j).text=str(col)
    for r in range(1,rows):
        for c in range(cols): tbl.cell(r,c).text=str(kpi.iloc[r-1,c])
prs.save(pptx_name); print("✓ PPTX kaydedildi:",pptx_name)

from google.colab import files
files.download(pptx_name)

"""Hedef Değişkeni, Özellik Mühendisliği, Veri Hazırlık"""

import numpy as np,pandas as pd
dfm=df_clean.copy()
thr=dfm['AbsentHours'].quantile(0.75)
dfm['HighAbsence']=(dfm['AbsentHours']>=thr).astype(int)
dfm['TenureBin']=pd.cut(dfm['LengthService'],bins=[0,1,3,5,100],labels=['0-1','1-3','3-5','5+'])
dfm['CityTop']=dfm['City'].where(dfm['City'].isin(dfm['City'].value_counts().head(10).index),'Other')
dfm['JobTop']=dfm['JobTitle'].where(dfm['JobTitle'].isin(dfm['JobTitle'].value_counts().head(10).index),'Other')
feat_cat=['Gender','DepartmentName','CityTop','JobTop','TenureBin','BusinessUnit','Division','StoreLocation']
feat_num=['Age','LengthService']
use_cols=feat_cat+feat_num+['HighAbsence']
dfm=dfm[use_cols].dropna()

"""özellik mühendisliği + modelleme + değerlendirme + önem listesi + risk özeti"""

# == 0) Gerekli kütüphaneler ==
import pandas as pd,numpy as np,matplotlib.pyplot as plt,os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,roc_auc_score,confusion_matrix,ConfusionMatrixDisplay

# == 1) Veriyi al: df_clean varsa onu kullan; yoksa yükle ve temel temizlik yap ==
try:
    df_clean
except NameError:
    try:
        from google.colab import files
        uploaded=files.upload(); csv_name=list(uploaded.keys())[0]; df=pd.read_csv(csv_name)
    except:
        raise SystemExit("CSV yüklenmedi. Colab kullanıyorsan dosyanı yükleyip tekrar çalıştır.")
    df_clean=df.copy()
    if 'Age' in df_clean.columns: df_clean.loc[df_clean['Age']<16,'Age']=np.nan; df_clean['Age']=df_clean['Age'].clip(lower=16,upper=80)
    if 'LengthService' in df_clean.columns: df_clean['LengthService']=df_clean['LengthService'].clip(lower=0,upper=df_clean['LengthService'].quantile(0.99))
    if 'AbsentHours' in df_clean.columns: df_clean['AbsentHours']=df_clean['AbsentHours'].clip(lower=0,upper=df_clean['AbsentHours'].quantile(0.99))
print("Veri şekli:",df_clean.shape)

# == 2) Hedef ve özellik mühendisliği ==
dfm=df_clean.copy()
if 'AbsentHours' not in dfm.columns: raise SystemExit("AbsentHours kolonu bulunamadı.")
thr=dfm['AbsentHours'].quantile(0.75)
dfm['HighAbsence']=(dfm['AbsentHours']>=thr).astype(int)
if 'LengthService' in dfm.columns and 'TenureBin' not in dfm.columns: dfm['TenureBin']=pd.cut(dfm['LengthService'],bins=[0,1,3,5,100],labels=['0-1','1-3','3-5','5+'])
if 'City' in dfm.columns: top_c=dfm['City'].value_counts().head(10).index; dfm['CityTop']=dfm['City'].where(dfm['City'].isin(top_c),'Other')
if 'JobTitle' in dfm.columns: top_j=dfm['JobTitle'].value_counts().head(10).index; dfm['JobTop']=dfm['JobTitle'].where(dfm['JobTitle'].isin(top_j),'Other')

# == 3) Özellik listelerini mevcut kolonlara göre otomatik kur ==
feat_cat=[c for c in ['Gender','DepartmentName','CityTop','JobTop','BusinessUnit','Division','StoreLocation','TenureBin'] if c in dfm.columns]
feat_num=[c for c in ['Age','LengthService'] if c in dfm.columns]
if len(feat_cat)+len(feat_num)==0: raise SystemExit("Kullanılabilir özellik bulunamadı.")
X=dfm[feat_cat+feat_num]; y=dfm['HighAbsence']
print("Kategorik:",feat_cat); print("Sayısal:",feat_num); print("NaN sayıları (ilk 10):\n",X.isna().sum().sort_values(ascending=False).head(10))

# == 4) Train/Test ayır ==
Xtr,Xte,Ytr,Yte=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

# == 5) Ön işleme + Modeller (imputer zorunlu!) ==
pre=ColumnTransformer([
    ('cat',Pipeline([('imp',SimpleImputer(strategy='most_frequent')),('ohe',OneHotEncoder(handle_unknown='ignore'))]),feat_cat),
    ('num',Pipeline([('imp',SimpleImputer(strategy='median')),('sc',StandardScaler())]),feat_num)
])
logit=Pipeline([('pre',pre),('clf',LogisticRegression(max_iter=1000,class_weight='balanced'))])
rf=Pipeline([('pre',pre),('clf',RandomForestClassifier(n_estimators=300,random_state=42,class_weight='balanced'))])

# == 6) Eğitim + Değerlendirme ==
for name,model in [('Logistic',logit),('RandomForest',rf)]:
    model.fit(Xtr,Ytr)
    p=model.predict(Xte); proba=model.predict_proba(Xte)[:,1]
    print(f"\n=== {name} ==="); print(classification_report(Yte,p,digits=3)); print("ROC-AUC:",roc_auc_score(Yte,proba))
    cm=confusion_matrix(Yte,p,labels=[0,1]); disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1]); fig,ax=plt.subplots(figsize=(3.5,3)); disp.plot(ax=ax,colorbar=False); plt.title(f"{name} Confusion Matrix"); plt.tight_layout(); plt.show()

# == 7) En iyi modeli seç (burada RF) ve özellik önemi yazdır ==
best=rf; best.fit(Xtr,Ytr)
try:
    ohe=best.named_steps['pre'].named_transformers_['cat'].named_steps['ohe']
    importances=best.named_steps['clf'].feature_importances_
    cat_names=ohe.get_feature_names_out(feat_cat) if len(feat_cat)>0 else np.array([])
    num_names=np.array(feat_num)
    feat_names=np.concatenate([cat_names,num_names]) if len(num_names)>0 else cat_names
    idx=np.argsort(importances)[::-1][:15]
    print("\nÖzellik Önemi (Top 15):")
    for i in idx: print(str(feat_names[i]),round(float(importances[i]),4))
except Exception as e:
    print("Özellik önemi çıkarılırken sorun:",e)

# == 8) Risk skoru ve departman özeti ==
proba=best.predict_proba(Xte)[:,1]
thr_score=0.7
risk_lbl=np.where(proba>=thr_score,'High','Low')
out=Xte.copy(); out['True']=Yte.values; out['RiskScore']=proba; out['RiskLabel']=risk_lbl
if 'DepartmentName' in out.columns:
    dept=out.assign(isHigh=(out['RiskLabel']=='High').astype(int)).groupby('DepartmentName')['isHigh'].agg(['mean','count']).sort_values('mean',ascending=False).head(15).rename(columns={'mean':'HighRiskRate','count':'N'})
    print("\nDepartman Bazlı HighRiskRate (Top 15):\n",dept)
else:
    print("\nDepartmentName kolonu yok, departman özeti atlandı.")
print("\nBitti ✔️")

"""**hiperparametre ayarı, eşik (threshold) optimizasyonu, ROC/PR grafikleri, model artefaktlarını kaydetme ve skorlanmış veri dışa aktarma**

RandomForest için Grid Search (5-kat CV, ROC-AUC)
"""

from sklearn.model_selection import StratifiedKFold,GridSearchCV
param_grid={"clf__n_estimators":[200,400],"clf__max_depth":[None,10,20],"clf__min_samples_split":[2,5],"clf__min_samples_leaf":[1,2]}
cv=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)
gs=GridSearchCV(rf,param_grid,scoring="roc_auc",cv=cv,n_jobs=-1,verbose=1)
gs.fit(Xtr,Ytr)
best=gs.best_estimator_
print("Best params:",gs.best_params_); print("CV ROC-AUC:",gs.best_score_)
p=best.predict(Xte); proba=best.predict_proba(Xte)[:,1]
from sklearn.metrics import classification_report,roc_auc_score
print(classification_report(Yte,p,digits=3)); print("Test ROC-AUC:",roc_auc_score(Yte,proba))

"""Eşik (threshold) optimizasyonu: Youden J ve En İyi F1"""

from sklearn.metrics import precision_recall_curve,roc_curve
fpr,tpr,thr=roc_curve(Yte,proba)
youden=tpr-fpr; thr_youden=float(thr[youden.argmax()])
prec,rec,thr2=precision_recall_curve(Yte,proba); f1=2*prec*rec/(prec+rec+1e-9)
thr_f1=float(thr2[f1[:-1].argmax()]) if len(thr2)>0 else 0.5
print("Best thr (Youden):",round(thr_youden,3),"| Best thr (F1):",round(thr_f1,3))
thr_use=thr_f1
pred_opt=(proba>=thr_use).astype(int)
print(classification_report(Yte,pred_opt,digits=3))

"""ROC ve Precision-Recall grafikleri"""

import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay,PrecisionRecallDisplay
fig=plt.figure(figsize=(5,4)); RocCurveDisplay.from_predictions(Yte,proba); plt.title("ROC"); plt.tight_layout(); plt.savefig("roc.png",dpi=150,bbox_inches="tight"); plt.show()
fig=plt.figure(figsize=(5,4)); PrecisionRecallDisplay.from_predictions(Yte,proba); plt.title("Precision-Recall"); plt.tight_layout(); plt.savefig("pr.png",dpi=150,bbox_inches="tight"); plt.show()

"""Özellik önemi ve CSV’ye dökme"""

import numpy as np,pandas as pd
ohe=best.named_steps['pre'].named_transformers_['cat'].named_steps['ohe'] if 'cat' in best.named_steps['pre'].named_transformers_ else None
cat_names=ohe.get_feature_names_out(feat_cat) if ohe is not None and len(feat_cat)>0 else np.array([])
num_names=np.array(feat_num)
feat_names=np.concatenate([cat_names,num_names]) if len(num_names)>0 else cat_names
imp=best.named_steps['clf'].feature_importances_
idx=np.argsort(imp)[::-1][:20]
feat_imp=pd.DataFrame({"feature":feat_names[idx],"importance":imp[idx]})
print(feat_imp); feat_imp.to_csv("feature_importance_top20.csv",index=False)

"""Skorlanmış test seti ve departman özeti"""

scored=Xte.copy(); scored["True"]=Yte.values; scored["Proba"]=proba; scored["Pred_opt"]=(proba>=thr_use).astype(int)
scored.to_csv("scored_test.csv",index=False)
if "DepartmentName" in scored.columns:
    dept=scored.assign(isHigh=(scored["Pred_opt"]==1).astype(int)).groupby("DepartmentName")["isHigh"].agg(["mean","count"]).sort_values("mean",ascending=False).rename(columns={"mean":"HighRiskRate","count":"N"})
    print(dept.head(15)); dept.reset_index().to_csv("dept_highrisk_summary.csv",index=False)

"""Modeli ve metadata’yı deployment için kaydet"""

import joblib,json
joblib.dump(best,"model_rf.pkl")
meta={"feat_cat":feat_cat,"feat_num":feat_num,"thr_use":thr_use}
with open("model_meta.json","w") as f: json.dump(meta,f)
print("Kaydedildi: model_rf.pkl, model_meta.json")

"""YENİ EKLENEN METRİKLERİ OTOMATİK RAPORLAMA"""

from docx import Document
from docx.shared import Inches
from matplotlib.backends.backend_pdf import PdfPages
import datetime as dt,os,numpy as np,pandas as pd,matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

stamp=dt.datetime.now().strftime("%Y-%m-%d_%H-%M")
pdf_name=f"Absenteeism_ExtendedReport_{stamp}.pdf"
docx_name=f"Absenteeism_ExtendedReport_{stamp}.docx"

# Güvenlik: gerekli dosyalar var mı?
need_imgs=[("roc.png","ROC Curve"),("pr.png","Precision-Recall Curve")]
missing=[p for p,_ in need_imgs if not os.path.exists(p)]
if missing: print("Uyarı: Eksik görseller:",missing,"(ROC/PR adımlarını önce çalıştırın)")

# == 1) PDF: ROC ve PR'ı ekle ==
with PdfPages(pdf_name) as pdf:
    for img,_ in need_imgs:
        if os.path.exists(img):
            fig=plt.figure(); ax=fig.add_subplot(111); ax.axis("off"); ax.imshow(plt.imread(img)); pdf.savefig(fig,bbox_inches="tight"); plt.close(fig)
    # Confusion Matrix'i de yeniden üretip PDF'e koy
    fig,ax=plt.subplots(figsize=(3.5,3)); ConfusionMatrixDisplay.from_predictions(Yte,pred_opt,ax=ax); plt.tight_layout(); pdf.savefig(fig,bbox_inches="tight"); plt.close(fig)

# == 2) WORD: Başlık ve açıklama ==
doc=Document()
doc.add_heading("Employee Absenteeism – Extended Report",0)
doc.add_paragraph(f"Oluşturma Tarihi: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')}")
doc.add_paragraph("Bu rapor; ROC/AUC ve Precision-Recall eğrileri, Confusion Matrix, Feature Importance (Top 20) ve Departman bazlı yüksek risk özeti tablolarını içerir.")

# ROC / PR / CM görsellerini ekle
for img,title in [("roc.png","ROC Curve"),("pr.png","Precision-Recall Curve")]:
    if os.path.exists(img):
        doc.add_heading(title,level=2); doc.add_picture(img,width=Inches(5))
# Confusion Matrix görselini kaydet ve ekle
cm_img="confusion.png"
fig,ax=plt.subplots(figsize=(3.5,3)); ConfusionMatrixDisplay.from_predictions(Yte,pred_opt,ax=ax); plt.tight_layout(); plt.savefig(cm_img,dpi=150); plt.close(fig)
if os.path.exists(cm_img):
    doc.add_heading("Confusion Matrix",level=2); doc.add_picture(cm_img,width=Inches(4))

# == 3) Feature Importance tablosu ==
if os.path.exists("feature_importance_top20.csv"):
    feat_imp=pd.read_csv("feature_importance_top20.csv")
    doc.add_heading("Feature Importance (Top 20)",level=2)
    t=doc.add_table(rows=1,cols=len(feat_imp.columns)); hdr=t.rows[0].cells
    for j,col in enumerate(feat_imp.columns): hdr[j].text=str(col)
    for _,row in feat_imp.iterrows():
        cells=t.add_row().cells
        for j,col in enumerate(feat_imp.columns): cells[j].text=str(row[col])
else:
    doc.add_paragraph("Not: feature_importance_top20.csv bulunamadı. Önce özellik önemi hücresini çalıştırın.")

# == 4) Departman bazlı High Risk özeti ==
if os.path.exists("dept_highrisk_summary.csv"):
    dept=pd.read_csv("dept_highrisk_summary.csv")
    # DepartmentName sütunu yoksa reset_index sonrası isim farklı olabilir, düzelt
    if "DepartmentName" not in dept.columns and "index" in dept.columns:
        dept.rename(columns={"index":"DepartmentName"},inplace=True)
    doc.add_heading("Departman Bazlı High Risk Oranları (Top 15)",level=2)
    cols=["DepartmentName"]+[c for c in dept.columns if c!="DepartmentName"]
    t=doc.add_table(rows=1,cols=len(cols)); hdr=t.rows[0].cells
    for j,col in enumerate(cols): hdr[j].text=str(col)
    for _,row in dept.head(15).iterrows():
        cells=t.add_row().cells
        for j,col in enumerate(cols):
            val=row[col] if col in dept.columns else ""
            if isinstance(val,(int,float,np.number)):
                cells[j].text=str(round(float(val),3))
            else:
                cells[j].text=str(val)
else:
    doc.add_paragraph("Not: dept_highrisk_summary.csv bulunamadı. Departman özeti hücresini çalıştırın.")

# == 5) Kaydet ve bilgi ver ==
doc.save(docx_name)
print("✓ PDF:",pdf_name)
print("✓ DOCX:",docx_name)

from google.colab import files
files.download("Absenteeism_ExtendedReport_2025-08-28_06-17.pdf")
files.download("Absenteeism_ExtendedReport_2025-08-28_06-17.docx")

"""**ipywidgets Tabanlı Etkileşimli Dashboard**"""

# === df_clean OLUŞTUR + DASHBOARD ===
import pandas as pd,numpy as np,matplotlib.pyplot as plt,os,io
from IPython.display import display,clear_output
import ipywidgets as w
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier

# 1) df_clean
try:
    df_clean
except NameError:
    try:
        from google.colab import files
        uploaded=files.upload(); csv_name=list(uploaded.keys())[0]; df=pd.read_csv(csv_name)
    except Exception as e:
        raise SystemExit("df_clean yok ve CSV yüklenmedi. Colab’de dosyanı yükleyip tekrar çalıştır.")
    df_clean=df.copy()
    if 'Age' in df_clean.columns: df_clean.loc[df_clean['Age']<16,'Age']=np.nan; df_clean['Age']=df_clean['Age'].clip(lower=16,upper=80)
    if 'LengthService' in df_clean.columns: df_clean['LengthService']=df_clean['LengthService'].clip(lower=0,upper=df_clean['LengthService'].quantile(0.99))
    if 'AbsentHours' in df_clean.columns: df_clean['AbsentHours']=df_clean['AbsentHours'].clip(lower=0,upper=df_clean['AbsentHours'].quantile(0.99))

# 2) Özellik mühendisliği (etiket + yardımcı kolonlar)
dfm=df_clean.copy()
if 'AbsentHours' not in dfm.columns: raise SystemExit("AbsentHours kolonu yok.")
thr_abs=dfm['AbsentHours'].quantile(0.75)
dfm['HighAbsence']=(dfm['AbsentHours']>=thr_abs).astype(int)
if 'LengthService' in dfm.columns and 'TenureBin' not in dfm.columns: dfm['TenureBin']=pd.cut(dfm['LengthService'],bins=[0,1,3,5,100],labels=['0-1','1-3','3-5','5+'])
if 'City' in dfm.columns: top_c=dfm['City'].value_counts().head(10).index; dfm['CityTop']=dfm['City'].where(dfm['City'].isin(top_c),'Other')
if 'JobTitle' in dfm.columns: top_j=dfm['JobTitle'].value_counts().head(15).index; dfm['JobTop']=dfm['JobTitle'].where(dfm['JobTitle'].isin(top_j),'Other')

feat_cat=[c for c in ['Gender','DepartmentName','CityTop','JobTop','BusinessUnit','Division','StoreLocation','TenureBin'] if c in dfm.columns]
feat_num=[c for c in ['Age','LengthService'] if c in dfm.columns]
if len(feat_cat)+len(feat_num)==0: raise SystemExit("Kullanılabilir özellik yok.")
X=dfm[feat_cat+feat_num]; y=dfm['HighAbsence']

# 3) Model (imputer’lı, hata vermez)
pre=ColumnTransformer([
    ('cat',Pipeline([('imp',SimpleImputer(strategy='most_frequent')),('ohe',OneHotEncoder(handle_unknown='ignore'))]),feat_cat),
    ('num',Pipeline([('imp',SimpleImputer(strategy='median')),('sc',StandardScaler())]),feat_num)
])
model=Pipeline([('pre',pre),('clf',RandomForestClassifier(n_estimators=300,random_state=42,class_weight='balanced'))])
Xtr,Xte,Ytr,Yte=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y); model.fit(Xtr,Ytr)

# 4) Dashboard widget’ları
dept_opts=sorted(dfm['DepartmentName'].dropna().unique().tolist()) if 'DepartmentName' in dfm.columns else []
city_opts=sorted(dfm['City'].dropna().unique().tolist()) if 'City' in dfm.columns else []
job_opts=sorted(dfm['JobTitle'].dropna().unique().tolist()) if 'JobTitle' in dfm.columns else []
m_dept=w.SelectMultiple(options=dept_opts,description='Departman',rows=10)
m_city=w.SelectMultiple(options=city_opts,description='Şehir',rows=10)
m_job=w.SelectMultiple(options=job_opts,description='Unvan',rows=10)
s_thr=w.FloatSlider(value=0.7,min=0.3,max=0.9,step=0.01,description='Risk Eşiği')
b_export=w.Button(description='Excel Dışa Aktar',button_style='success')
out=w.Output()

def current_filter(df):
    f=df.copy()
    if len(m_dept.value)>0 and 'DepartmentName' in f.columns: f=f[f['DepartmentName'].isin(list(m_dept.value))]
    if len(m_city.value)>0 and 'City' in f.columns: f=f[f['City'].isin(list(m_city.value))]
    if len(m_job.value)>0 and 'JobTitle' in f.columns: f=f[f['JobTitle'].isin(list(m_job.value))]
    return f

def kpi_tables(f):
    kpis={}
    total=f['AbsentHours'].sum() if 'AbsentHours' in f.columns else np.nan
    per_cap=f['AbsentHours'].mean() if 'AbsentHours' in f.columns else np.nan
    n=len(f)
    kpis['Genel']=pd.DataFrame([{'ToplamAbsentHours':round(float(total),2) if pd.notna(total) else None,'KisiBasiOrtalama':round(float(per_cap),2) if pd.notna(per_cap) else None,'KayıtSayısı':int(n)}])
    if 'DepartmentName' in f.columns: kpis['DepartmanTop10']=f.groupby('DepartmentName')['AbsentHours'].sum().sort_values(ascending=False).head(10).rename('Sum').reset_index()
    if 'City' in f.columns: kpis['SehirTop10']=f.groupby('City')['AbsentHours'].sum().sort_values(ascending=False).head(10).rename('Sum').reset_index()
    if 'JobTitle' in f.columns: kpis['UnvanTop10']=f.groupby('JobTitle')['AbsentHours'].sum().sort_values(ascending=False).head(10).rename('Sum').reset_index()
    return kpis

def plot_bar(s,title,xlabel):
    fig=plt.figure(figsize=(8,3.2)); s.plot(kind='bar'); plt.title(title); plt.xlabel(xlabel); plt.ylabel('Toplam AbsentHours'); plt.xticks(rotation=45); plt.tight_layout(); return fig

def refresh(_=None):
    with out:
        clear_output(wait=True)
        f=current_filter(dfm)
        if f.empty: print("Filtre sonucu kayıt yok."); return
        proba=model.predict_proba(f[feat_cat+feat_num])[:,1]
        f=f.assign(RiskScore=proba,RiskLabel=np.where(proba>=s_thr.value,'High','Low'))
        print(f"Toplam Kayıt: {len(f)} | Yüksek Risk Oranı: {round((f['RiskLabel']=='High').mean()*100,2)}% | Eşik: {round(s_thr.value,2)}")
        kpis=kpi_tables(f); display(kpis['Genel'])
        if 'DepartmanTop10' in kpis:
            fig=plot_bar(kpis['DepartmanTop10'].set_index('DepartmentName')['Sum'],"Top 10 Departman (Toplam AbsentHours)","DepartmentName"); display(fig); plt.close(fig)
        if 'SehirTop10' in kpis:
            fig=plot_bar(kpis['SehirTop10'].set_index('City')['Sum'],"Top 10 Şehir (Toplam AbsentHours)","City"); display(fig); plt.close(fig)
        if 'UnvanTop10' in kpis:
            fig=plot_bar(kpis['UnvanTop10'].set_index('JobTitle')['Sum'],"Top 10 Unvan (Toplam AbsentHours)","JobTitle"); display(fig); plt.close(fig)
        if 'DepartmentName' in f.columns:
            dept=f.assign(isHigh=(f['RiskLabel']=='High').astype(int)).groupby('DepartmentName')['isHigh'].agg(['mean','count']).sort_values('mean',ascending=False).rename(columns={'mean':'HighRiskRate','count':'N'}).head(20).reset_index()
            print("Departman Bazlı Yüksek Risk Özeti (Top 20):"); display(dept)
        def do_export(btn):
            to_save={'Genel':kpis['Genel']}
            if 'DepartmentName' in f.columns:
                to_save['DeptRisk']=f.assign(isHigh=(f['RiskLabel']=='High').astype(int)).groupby('DepartmentName')['isHigh'].agg(['mean','count']).rename(columns={'mean':'HighRiskRate','count':'N'}).reset_index()
            with pd.ExcelWriter("dashboard_export.xlsx") as xw:
                for name,dfx in to_save.items(): dfx.to_excel(xw,sheet_name=name,index=False)
            print("Kaydedildi: dashboard_export.xlsx (Files panelinden indir)")
        b_export.on_click(do_export)

refresh()
for wid in [m_dept,m_city,m_job,s_thr]: wid.observe(refresh,names='value')
ui=w.HBox([w.VBox([m_dept,m_city,m_job,s_thr,b_export],layout=w.Layout(width='35%')),w.VBox([out],layout=w.Layout(width='65%'))])
display(ui)